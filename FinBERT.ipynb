{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8fy79wk1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">denim-bee-2</strong>: <a href=\"https://wandb.ai/noobsaswata/FinBERT/runs/8fy79wk1\" target=\"_blank\">https://wandb.ai/noobsaswata/FinBERT/runs/8fy79wk1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220310_194134-8fy79wk1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8fy79wk1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\saswa\\saswata\\NLP_Practice\\wandb\\run-20220310_195944-3bwh7pk1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/noobsaswata/FinBERT/runs/3bwh7pk1\" target=\"_blank\">tough-hill-3</a></strong> to <a href=\"https://wandb.ai/noobsaswata/FinBERT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run= wandb.init(project='FinBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(r'C:\\Users\\saswa\\saswata\\stockerbot-export.csv', header=0)\n",
    "df= pd.DataFrame(df.loc[:50,'text'])\n",
    "type(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 252/252 [00:00<00:00, 253kB/s]\n",
      "Downloading: 100%|██████████| 758/758 [00:00<00:00, 756kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:01<00:00, 175kB/s]  \n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n",
      "Downloading: 100%|██████████| 418M/418M [00:57<00:00, 7.67MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tok= AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model= AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_lst= list(df['text'])\n",
    "for i in range(len(tweet_lst)):\n",
    "    tweet_lst[i]= tweet_lst[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0489, 0.0420, 0.9091],\n",
       "        [0.0087, 0.9590, 0.0323],\n",
       "        [0.0196, 0.1441, 0.8363],\n",
       "        [0.1431, 0.0202, 0.8367],\n",
       "        [0.0449, 0.0246, 0.9305],\n",
       "        [0.0287, 0.0271, 0.9442],\n",
       "        [0.0275, 0.0573, 0.9152],\n",
       "        [0.0388, 0.0382, 0.9230],\n",
       "        [0.0303, 0.0261, 0.9436],\n",
       "        [0.0969, 0.0221, 0.8809],\n",
       "        [0.2701, 0.1183, 0.6116],\n",
       "        [0.3281, 0.0094, 0.6625],\n",
       "        [0.1921, 0.0475, 0.7604],\n",
       "        [0.0111, 0.9683, 0.0206],\n",
       "        [0.0116, 0.9503, 0.0382],\n",
       "        [0.5709, 0.0825, 0.3466],\n",
       "        [0.0691, 0.0463, 0.8846],\n",
       "        [0.0432, 0.6563, 0.3005],\n",
       "        [0.0869, 0.0210, 0.8921],\n",
       "        [0.0445, 0.2127, 0.7428],\n",
       "        [0.0366, 0.1510, 0.8124],\n",
       "        [0.1516, 0.0113, 0.8371],\n",
       "        [0.7592, 0.0118, 0.2290],\n",
       "        [0.0122, 0.9670, 0.0208],\n",
       "        [0.0174, 0.3133, 0.6694],\n",
       "        [0.0769, 0.0213, 0.9018],\n",
       "        [0.0328, 0.0284, 0.9388],\n",
       "        [0.0391, 0.0190, 0.9419],\n",
       "        [0.0722, 0.0232, 0.9045],\n",
       "        [0.0657, 0.0235, 0.9109],\n",
       "        [0.1162, 0.8168, 0.0670],\n",
       "        [0.8644, 0.0146, 0.1210],\n",
       "        [0.0345, 0.0313, 0.9342],\n",
       "        [0.0386, 0.1067, 0.8547],\n",
       "        [0.0396, 0.0412, 0.9192],\n",
       "        [0.0318, 0.0288, 0.9394],\n",
       "        [0.0427, 0.0966, 0.8607],\n",
       "        [0.0256, 0.0320, 0.9424],\n",
       "        [0.0283, 0.0285, 0.9432],\n",
       "        [0.0430, 0.1351, 0.8219],\n",
       "        [0.0294, 0.0309, 0.9396],\n",
       "        [0.0304, 0.0310, 0.9386],\n",
       "        [0.0879, 0.0279, 0.8842],\n",
       "        [0.0352, 0.0383, 0.9264],\n",
       "        [0.4135, 0.0243, 0.5622],\n",
       "        [0.0720, 0.0165, 0.9115],\n",
       "        [0.3724, 0.0489, 0.5787],\n",
       "        [0.0216, 0.0505, 0.9279],\n",
       "        [0.0184, 0.1118, 0.8697],\n",
       "        [0.0105, 0.9034, 0.0862],\n",
       "        [0.1171, 0.1434, 0.7395]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input= tok(list(df['text']), padding= True, truncation=True, return_tensors='pt') #padding: 0 will be added in matrices of each tweet for uniform lenght.\n",
    "                                                                            #truncation is used to keep the length of each sequence within the maximum limit of tokenizer to process.\n",
    "                                                                            # 'pt' for pytorch tensor\n",
    "output= model(**input)\n",
    "pred= torch.nn.functional.softmax(output.logits, dim=-1)        #logit maps probability values from 0,1 to -infinity to +infinity\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b83752dd2351e549d4486d00579c2754387b6552781a235cfc636d34e5e38ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
