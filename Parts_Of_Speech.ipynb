{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(u\"The drunk nigger drove his car into a crowd and killed 4 people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The drunk nigger drove his car into a crowd and killed 4 people\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The                 ----DET       -----determiner \n",
      "drunk               ----ADJ       -----adjective \n",
      "nigger              ----NOUN      -----noun \n",
      "drove               ----VERB      -----verb \n",
      "his                 ----PRON      -----pronoun \n",
      "car                 ----NOUN      -----noun \n",
      "into                ----ADP       -----adposition \n",
      "a                   ----DET       -----determiner \n",
      "crowd               ----NOUN      -----noun \n",
      "and                 ----CCONJ     -----coordinating conjunction \n",
      "killed              ----VERB      -----verb \n",
      "4                   ----NUM       -----numeral \n",
      "people              ----NOUN      -----noun \n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(f'{tok.text:{20}}----{tok.pos_:{10}}-----{spacy.explain(tok.pos_)} ')             #.tag/.pos will give the numeric reference, .tag_/.pos_ will give the actual name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The                 -----DT                  -----determiner \n",
      "drunk               -----JJ                  -----adjective (English), other noun-modifier (Chinese) \n",
      "nigger              -----NN                  -----noun, singular or mass \n",
      "drove               -----VBD                 -----verb, past tense \n",
      "his                 -----PRP$                -----pronoun, possessive \n",
      "car                 -----NN                  -----noun, singular or mass \n",
      "into                -----IN                  -----conjunction, subordinating or preposition \n",
      "a                   -----DT                  -----determiner \n",
      "crowd               -----NN                  -----noun, singular or mass \n",
      "and                 -----CC                  -----conjunction, coordinating \n",
      "killed              -----VBD                 -----verb, past tense \n",
      "4                   -----CD                  -----cardinal number \n",
      "people              -----NNS                 -----noun, plural \n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(f'{tok.text:{20}}-----{tok.tag_:20}-----{spacy.explain(tok.tag_)} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts= doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET                 -------2 \n",
      "ADJ                 -------1 \n",
      "NOUN                -------4 \n",
      "VERB                -------2 \n",
      "PRON                -------1 \n",
      "ADP                 -------1 \n",
      "CCONJ               -------1 \n",
      "NUM                 -------1 \n"
     ]
    }
   ],
   "source": [
    "for (k,v) in pos_counts.items():\n",
    "    print(f'{doc.vocab[k].text:{20}}-------{v} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts= doc.count_by(spacy.attrs.TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determiner                                        --------2 \n",
      "adjective (English), other noun-modifier (Chinese)--------1 \n",
      "noun, singular or mass                            --------3 \n",
      "verb, past tense                                  --------2 \n",
      "pronoun, possessive                               --------1 \n",
      "conjunction, subordinating or preposition         --------1 \n",
      "conjunction, coordinating                         --------1 \n",
      "cardinal number                                   --------1 \n",
      "noun, plural                                      --------1 \n"
     ]
    }
   ],
   "source": [
    "for (k,v) in tag_counts.items():\n",
    "    tag= doc.vocab[k].text\n",
    "    print(f'{spacy.explain(tag):{50}}--------{v} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_counts= doc.count_by(spacy.attrs.DEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determiner---------2 \n",
      "adjectival modifier---------1 \n",
      "nominal subject---------1 \n",
      "None---------1 \n",
      "possession modifier---------1 \n",
      "direct object---------2 \n",
      "prepositional modifier---------1 \n",
      "object of preposition---------1 \n",
      "coordinating conjunction---------1 \n",
      "conjunct---------1 \n",
      "numeric modifier---------1 \n"
     ]
    }
   ],
   "source": [
    "for (k,v) in dep_counts.items():\n",
    "    dep= doc.vocab[k].text\n",
    "    print(f\"{spacy.explain(dep)}---------{v} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if len(doc.ents) == 0:\n",
    "        print(\"No entitiies found\")\n",
    "    else:\n",
    "        for ent in doc.ents:\n",
    "            print(f'{ent.text}-------{ent.label_}------{spacy.explain(ent.label_)} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-------CARDINAL------Numerals that do not fall under another type \n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raneld-------PERSON------People, including fictional \n",
      "Mazda RX7-------ORG------Companies, agencies, institutions, etc. \n"
     ]
    }
   ],
   "source": [
    "show_ents(nlp(u'Raneld bought a new Mazda RX7 with LS7 swapped for drifting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1, doc2= nlp(u\"I swapped a Hell_ inside my RX7.\"), nlp(u\"Hell_ is my engine of choice for a track car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RX7-------ORG------Companies, agencies, institutions, etc. \n"
     ]
    }
   ],
   "source": [
    "show_ents(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS7-------GPE------Countries, cities, states \n",
      "Celica-------PRODUCT------Objects, vehicles, foods, etc. (not services) \n"
     ]
    }
   ],
   "source": [
    "show_ents(nlp(u\"I swapped an LS7 engine inside my Celica AWD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are going to add \"Hell_\" inside the PRODUCT entity.  \n",
    "#We couldnt have added \"LS7\" inside the PRODUCT entity cuz it already had an entity defined for it.\n",
    "PRODUCT= doc1.vocab.strings[u\"PRODUCT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ent= Span(doc1, 3,4, label= PRODUCT)\n",
    "type(new_ent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1.ents= tuple(list(doc1.ents)+[new_ent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hell-------PRODUCT------Objects, vehicles, foods, etc. (not services) \n",
      "RX7-------ORG------Companies, agencies, institutions, etc. \n"
     ]
    }
   ],
   "source": [
    "show_ents(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vac= nlp(u'This is the new vacuum cleaner in the market.'u'This is the vacuum-cleaner I will be using')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entitiies found\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher= PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list= ['vacuum cleaner', 'vacuum-cleaner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_pattern= [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('Vac_Clean', None, *phrase_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches= matcher(doc_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11464633557851095265, 4, 6), (11464633557851095265, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, adding the two different types of vacuum cleaner in the PRODUCT tag\n",
    "PROD= doc_vac.vocab.strings[u'PRODUCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vacuum cleaner, vacuum-cleaner]\n"
     ]
    }
   ],
   "source": [
    "new_ents_vac= [Span(doc_vac, match[1], match[2]) for match in matches]\n",
    "print(new_ents_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "doc_vac.ents= tuple(list(doc_vac.ents) + new_ents_vac)\n",
    "print(doc_vac.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entitiies found\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc_vac.ents if ent.label_==\"PRODUCT\"])         #For seeing the number of a particualr entity in a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "the\n",
      "new\n",
      "vacuum\n",
      "cleaner\n",
      "in\n",
      "the\n",
      "market\n",
      ".\n",
      "This\n",
      "is\n",
      "the\n",
      "vacuum\n",
      "-\n",
      "cleaner\n",
      "I\n",
      "will\n",
      "be\n",
      "using\n"
     ]
    }
   ],
   "source": [
    "for tok in doc_vac:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sent= nlp(u\"This is the new vacuum cleaner in the market.This is the new vacuum cleaner in the market.This is the new vacuum cleaner in the market. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the new vacuum cleaner in the market.\n",
      "This is the new vacuum cleaner in the market.\n",
      "This is the new vacuum cleaner in the market.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc_sent.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sent.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the new vacuum cleaner in the market.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(doc_sent.sents)[0])\n",
    "type(list(doc_sent.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the new vacuum cleaner in the market.This is the vacuum-cleaner I will be using'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vac.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(u'\"Your management is doing quiet well. Keep it up; hope we can double our revenue this year\" -Dilip Singh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Your management is doing quiet well; hope we can double our revenue this year\" -Dilip Singh'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Your management is doing quiet well. Keep it up;\n",
      "hope we can double our revenue this year\" -Dilip Singh\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For correctly segmenting the above doc, we are creating a new SEGMENTATION RULE\n",
    "from spacy.language import Language\n",
    "@Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if  token.text==\";\":\n",
    "            doc[token.i+1].is_sent_start= True                  #token.i gives the index position.\n",
    "        else:\n",
    "            doc[token.i+1].is_sent_start= False\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('set_custom_boundaries', before= 'parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp.remove_pipe('set_custom_boundaries')\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Your management is doing quiet well.\n",
      "Keep it up; hope we can double our revenue this year\" -Dilip Singh\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1= nlp(u'Sentence 1. Sentence\\n. sentence 2\\nsex. \\n')\n",
    "doc2= nlp(u'This is a sent. This is another sent.\\n\\n. This is another')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sent.\n",
      "This is another sent.\n",
      "\n",
      "\n",
      ".\n",
      "This is another\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This------0 \n",
      "is------1 \n",
      "a------2 \n",
      "sent------3 \n",
      ".------4 \n",
      "This------5 \n",
      "is------6 \n",
      "another------7 \n",
      "sent------8 \n",
      ".------9 \n",
      "\n",
      "\n",
      "------10 \n",
      ".------11 \n",
      "This------12 \n",
      "is------13 \n",
      "another------14 \n"
     ]
    }
   ],
   "source": [
    "for w in doc2:\n",
    "    print(f'{w.text}------{w.i} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def newline_segment(doc):                   #It segments the sentence based on new line '\\n\n",
    "    start=0\n",
    "    new_line= False\n",
    "    for word in doc:\n",
    "        if new_line:\n",
    "            yield doc[start:word.i]\n",
    "            start= word.i\n",
    "            new_line= False\n",
    "        elif word.text=='\\n':\n",
    "            new_line= True\n",
    "    yield doc[start:]'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component('new_line_bound')\n",
    "def new_line_bound(doc):\n",
    "    for tok in doc[:-1]:\n",
    "        if tok.text=='\\n':\n",
    "            doc[tok.i+1].is_sent_start= True\n",
    "        else:\n",
    "            doc[tok.i+1].is_sent_start= False\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'new_line_bound',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('new_line_bound', before= 'parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe('new_line_bound')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(doc1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1. Sentence\n",
      "\n",
      ". sentence 2\n",
      "\n",
      "sex. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b83752dd2351e549d4486d00579c2754387b6552781a235cfc636d34e5e38ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
